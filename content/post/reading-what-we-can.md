+++
date = 2024-04-10
draft = false
title = 'Reading what we can'
[params]
  author = 'Dan Johansson'
+++

# Reading What We Can - The Gauntlet

While attending an Apart Research: [https://www.apartresearch.com/](https://www.apartresearch.com/) sprint/hackathon, I was introduced by Esben Kran: [https://twitter.com/EsbenKC](https://twitter.com/EsbenKC) to the "Reading What We Can" challenge. This challenge involves reading a combination of 20 books and articles over 20 days within your chosen learning path. In my case, it's the "ML Engineering & AI Safety" path as defined on the challenge website. The purpose of this challenge is to consume and learn from important material, but also to frame learning as a digestible challenge.

I'll be updating this post with short thoughts and summaries of each reading material as I progress. Hopefully, this inspires someone to take on the challenge or at least explore some of these readings!

## Reading List

* Day 1: [*Preventing an AI-related catastrophe*](https://80000hours.org/problem-profiles/artificial-intelligence/)

## Day 1: [*Preventing an AI-related catastrophe*](https://80000hours.org/problem-profiles/artificial-intelligence/)

**Summary:** 
- many experts think that the is a change of catastrophic AI effects
- The author compares the resent growth of AI capabilities and investment to the industrial revolution.
- Algorithm efficacy, data and compute is evolving exponentially and they all lead to more powerful AI. 
- Powerful AI is concerning since they might seeking power
- The incentives to create powerful AI is high since it can allow its creator to have become powerful or rich.
- A planning AI system will develop instrumental goals which helps it active its main goal. Things like political power and money will most likely make any primary goal more achievable meaning that these are very likely instrumental goals.

TBC



**Thoughts:** 
*Raises some thought-provoking points...* 




