+++
date = 2024-04-10
draft = false
title = 'Reading What We Can - The Gauntlet'
[params]
  author = 'Dan Johansson'
  ShowToc= true
  ShowReadingTime= true
+++

While attending an Apart Research: [https://www.apartresearch.com/](https://www.apartresearch.com/) sprint/hackathon, I was introduced by Esben Kran: [https://twitter.com/EsbenKC](https://twitter.com/EsbenKC) to the "Reading What We Can" challenge. This challenge involves reading a combination of 20 books and articles over 20 days within your chosen learning path. In my case, it's the "ML Engineering & AI Safety" path as defined on the challenge website. The purpose of this challenge is to consume and learn from important material, but also to frame learning as a digestible challenge.

I'll be updating this post with short thoughts and summaries of each reading material as I progress. Hopefully, this inspires someone to take on the challenge or at least explore some of these readings!

## Reading List

* Day 1: [*Preventing an AI-related catastrophe*](https://80000hours.org/problem-profiles/artificial-intelligence/)

## Day 1: [*Preventing an AI-related catastrophe*](https://80000hours.org/problem-profiles/artificial-intelligence/)

**Summary:** 
- many experts think that the is a change of catastrophic AI effects
- The author compares the resent growth of AI capabilities and investment to the industrial revolution.
- Algorithm efficacy, data and compute is evolving exponentially and they all lead to more powerful AI. 
- Powerful AI is concerning since they might seeking power
- The incentives to create powerful AI is high since it can allow its creator to have become powerful or rich.
- A planning AI system will develop instrumental goals which helps it active its main goal. Things like political power and money will most likely make any primary goal more achievable meaning that these are very likely instrumental goals.
- Misalignment is very difficult to ensure. There are real examples of agents seemingly learning a goal but then fail to generalise when in a new environment leading unexpected behaviour.

Cont at "Disempowerment by AI systems would be an existential catastrophe"



**Thoughts:** 
*Raises some thought-provoking points...* 




